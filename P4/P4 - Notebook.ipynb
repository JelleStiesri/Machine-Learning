{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine-Learning Practicum 4 [Backpropagation]\n",
    "#### Door Jelle Stiesri | 12-3-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neuron import *\n",
    "from NeuronLayer import *\n",
    "from NeuronNetwork import *\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maken van een waarheidstabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Deze functie is ervoor bedoelt om makkelijker weer te kunnen geven of een output True or False \n",
    "representeert. Dit kan alleen bij neurons waar je bijvoorbeeld een logische poort mee wilt simuleren\"\"\"\n",
    "\n",
    "def trueORfalse(output):\n",
    "    result = []\n",
    "    for number in output:\n",
    "        if number < 0.5:\n",
    "            result.append(False)\n",
    "        elif number > 0.95:\n",
    "            result.append(True)\n",
    "        else:\n",
    "            result.append(number)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_data(function, expectations):\n",
    "    \"\"\"Deze functie berekent de uitkomst van een Neuron/netwerk en geeft dit terug in een goed format\"\"\"\n",
    "    data = []\n",
    "\n",
    "    for item in expectations:\n",
    "        output = function(item[0])\n",
    "        if type(output) != list:\n",
    "            output = [output]\n",
    "        data.append([item[0], trueORfalse(output)])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(data, caption):\n",
    "    \"\"\"Deze functie print een waarheidstabel\"\"\"\n",
    "    columns = ['Input', 'Output']\n",
    "    \n",
    "    df = pd.DataFrame.from_records(data, columns=columns)\n",
    "    print(f'<{caption}>\\n {df}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x):\n",
    "    \"\"\"Deze functie classificeert een lijst met outputs tot 1 output. Dit is de hoogste output\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))  # Voert het softmax algoritme uit zodat je uitkomsten beter kan classificeren\n",
    "    softmax = e_x / e_x.sum(axis=0) \n",
    "\n",
    "    return np.where(softmax == np.amax(softmax))[0][0]  # returnt de index van de hoogste waarde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_outcome_binary_table(expectation, outcome):\n",
    "    assert expectation == outcome, 'Test mislukt - Verwachting & uitkomst niet hetzelfde'\n",
    "    print(\"Test geslaagd - Verwachting & uitkomst hetzelfde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random startwaarden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_float():\n",
    "    return round(random.uniform(-10, 10),1)\n",
    "\n",
    "def generate_random_list(numbers):\n",
    "    lst = []\n",
    "    for item in range(numbers):\n",
    "        lst.append(generate_random_float())\n",
    "    \n",
    "    return [float(i)/max(lst) for i in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AND port>\n",
      "- Bias = -8.3\n",
      "- Weights = [4.304347826086957, 1.0]\n",
      "\n",
      "<Verwachting>\n",
      "             Input  Output\n",
      "0  [False, False]   False\n",
      "1   [False, True]   False\n",
      "2   [True, False]   False\n",
      "3    [True, True]    True\n",
      "\n",
      "<Uitkomst VOOR training>\n",
      "             Input   Output\n",
      "0  [False, False]  [False]\n",
      "1   [False, True]  [False]\n",
      "2   [True, False]  [False]\n",
      "3    [True, True]  [False]\n",
      "\n",
      "<Uitkomst Na Training>\n",
      "             Input   Output\n",
      "0  [False, False]  [False]\n",
      "1   [False, True]  [False]\n",
      "2   [True, False]  [False]\n",
      "3    [True, True]   [True]\n",
      "\n",
      "<AND port>\n",
      "- Bias = -13.59723420525501\n",
      "- Weights = [9.008199886811449, 9.008209399082276]\n",
      "\n",
      "Test geslaagd - Verwachting & uitkomst hetzelfde\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AND Test\"\"\"\n",
    "\n",
    "n_and = Neuron('AND', generate_random_float(), generate_random_list(2))\n",
    "print(n_and)\n",
    "\n",
    "and_expectation = [[[False, False], False],  # Verwachtingen\n",
    "                   [[False, True], False], \n",
    "                   [[True, False], False], \n",
    "                   [[True, True], True]]\n",
    "\n",
    "print_table(and_expectation, 'Verwachting')\n",
    "\n",
    "old_output = create_table_data(n_and.activation, and_expectation) \n",
    "print_table(old_output, 'Uitkomst VOOR training')\n",
    "\n",
    "# Trainen van losse neuron\n",
    "epochs = 2500\n",
    "for i in range(epochs):\n",
    "    random.shuffle(and_expectation)\n",
    "    for input_list, expectation in and_expectation:\n",
    "\n",
    "        output = n_and.activation(input_list)\n",
    "        n_and.calculate_error_output(n_and.output, expectation)\n",
    "        n_and.update(input_list, 10)\n",
    "\n",
    "and_expectation = [[[False, False], [False]],  # Omdat de eerste dataset is geshuffled\n",
    "                   [[False, True], [False]], \n",
    "                   [[True, False], [False]], \n",
    "                   [[True, True], [True]]]\n",
    "\n",
    "new_output = create_table_data(n_and.activation, and_expectation)\n",
    "print_table(new_output, 'Uitkomst Na Training')\n",
    "\n",
    "print(n_and)\n",
    "\n",
    "test_outcome_binary_table(and_expectation, new_output) # Test de uitkomst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Verwachting>\n",
      "             Input   Output\n",
      "0  [False, False]  [False]\n",
      "1   [False, True]   [True]\n",
      "2   [True, False]   [True]\n",
      "3    [True, True]  [False]\n",
      "\n",
      "<Uitkomst VOOR training>\n",
      "             Input                Output\n",
      "0  [False, False]  [0.6059468015087622]\n",
      "1   [False, True]  [0.6631895793149735]\n",
      "2   [True, False]  [0.6631895793149735]\n",
      "3    [True, True]  [0.7188238810813806]\n",
      "\n",
      "<Uitkomst NA training>\n",
      "             Input   Output\n",
      "0  [False, False]  [False]\n",
      "1   [False, True]   [True]\n",
      "2   [True, False]   [True]\n",
      "3    [True, True]  [False]\n",
      "\n",
      "Test geslaagd - Verwachting & uitkomst hetzelfde\n"
     ]
    }
   ],
   "source": [
    "\"\"\"XOR Test\"\"\"\n",
    "\n",
    "N1 = Neuron('Neuron 1', -1, [1, 1])\n",
    "N2 = Neuron('Neuron 2', -1, [0.5, 0.5])\n",
    "outputNeuron = Neuron('Output Neuron', 0, [0.6, 1])\n",
    "\n",
    "hiddenLayer = NeuronLayer('Hidden Layer', [N1, N2])\n",
    "outputLayer = NeuronLayer('Output Layer', [outputNeuron])\n",
    "\n",
    "network_xor = NeuronNetwork([hiddenLayer, outputLayer])\n",
    "\n",
    "xor_expectation = [[[False, False], [False]],\n",
    "                   [[False, True], [True]],\n",
    "                   [[True, False], [True]],\n",
    "                   [[True, True], [False]]]\n",
    "\n",
    "print_table(xor_expectation, \"Verwachting\")\n",
    "\n",
    "old_output = create_table_data(network_xor.feed_forward, xor_expectation)\n",
    "print_table(old_output, 'Uitkomst VOOR training')\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 10\n",
    "network_xor.train(xor_expectation, epochs, learning_rate) # Trainen van het netwerk\n",
    "\n",
    "xor_expectation = [[[False, False], [False]],\n",
    "                   [[False, True], [True]],\n",
    "                   [[True, False], [True]],\n",
    "                   [[True, True], [False]]]\n",
    "\n",
    "new_output = create_table_data(network_xor.feed_forward, xor_expectation)\n",
    "print_table(new_output, 'Uitkomst NA training')\n",
    "\n",
    "test_outcome_binary_table(xor_expectation, new_output) # Test de uitkomst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Dit netwerk bestaat uit 2 layers\n",
      "\n",
      "<Verwachting>\n",
      "             Input          Output\n",
      "0  [False, False]  [False, False]\n",
      "1   [False, True]   [True, False]\n",
      "2   [True, False]   [True, False]\n",
      "3    [True, True]   [False, True]\n",
      "\n",
      "<Uitkomst VOOR training>\n",
      "             Input                                   Output\n",
      "0  [False, False]                           [False, False]\n",
      "1   [False, True]                           [False, False]\n",
      "2   [True, False]                           [False, False]\n",
      "3    [True, True]  [0.5521287167773176, 0.519279377518996]\n",
      "\n",
      "<Uitkomst NA training>\n",
      "             Input          Output\n",
      "0  [False, False]  [False, False]\n",
      "1   [False, True]   [True, False]\n",
      "2   [True, False]   [True, False]\n",
      "3    [True, True]   [False, True]\n",
      "\n",
      "Test geslaagd - Verwachting & uitkomst hetzelfde\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ADDER Test\"\"\"\n",
    "\n",
    "N1 = Neuron('Neuron 1', 0, [1, 1])\n",
    "N2 = Neuron('Neuron 2', 0, [1, 1])\n",
    "N3 = Neuron('Neuron 3', 0, [1, 1])\n",
    "\n",
    "outputNeuron1 = Neuron('Output Neuron', -1.2, [0.5, 0.1, 1])\n",
    "outputNeuron2 = Neuron('Output Neuron', -1.2, [0.5, 0.15, 0.8])\n",
    "\n",
    "hiddenLayer = NeuronLayer('Hidden Layer', [N1, N2, N3])\n",
    "outputLayer = NeuronLayer('Output Layer', [outputNeuron1, outputNeuron2])\n",
    "\n",
    "network_adder = NeuronNetwork([hiddenLayer, outputLayer])\n",
    "print(network_adder)\n",
    "\n",
    "adder_expectation = [[[False, False], [False, False]],\n",
    "                   [[False, True], [True, False]],\n",
    "                   [[True, False], [True, False]],\n",
    "                   [[True, True], [False, True]]]\n",
    "\n",
    "print_table(adder_expectation, \"Verwachting\")\n",
    "\n",
    "old_output = create_table_data(network_adder.feed_forward, adder_expectation)\n",
    "print_table(old_output, 'Uitkomst VOOR training')\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 10\n",
    "network_adder.train(adder_expectation, epochs, learning_rate)\n",
    "\n",
    "adder_expectation = [[[False, False], [False, False]],\n",
    "                   [[False, True], [True, False]],\n",
    "                   [[True, False], [True, False]],\n",
    "                   [[True, True], [False, True]]]\n",
    "\n",
    "\n",
    "\n",
    "new_output = create_table_data(network_adder.feed_forward, adder_expectation)\n",
    "print_table(new_output, 'Uitkomst NA training')\n",
    "\n",
    "\n",
    "test_outcome_binary_table(adder_expectation, new_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_data_iris(function, expectations):\n",
    "    data = []\n",
    "    outputs = []\n",
    "\n",
    "    for item in expectations:\n",
    "        output = function(item[0])\n",
    "        outputs.append(classify(output))\n",
    "        data.append([item[0], classify(output)])\n",
    "#         data.append([item[0], output])\n",
    "    return data, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris(as_frame=True)\n",
    "data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train / Test Split\"\"\"\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(data['data'], data['target'], test_size=0.33, shuffle = True)\n",
    "\n",
    "targets_train = pd.get_dummies(targets_train).values.tolist() \n",
    "features_train = features_train.values.tolist()\n",
    "features_test = features_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iris = [list(x) for x in zip(features_train, targets_train)]\n",
    "test_iris = [list(x) for x in zip(features_test, targets_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Dit netwerk bestaat uit 2 layers\n",
      "\n",
      "Score [Voor training]: <0.34>\n",
      "\n",
      "Score [Na training]: <0.9>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"IRIS Test\"\"\"\n",
    "\n",
    "N1 = Neuron('Neuron 1', 0, [0.2, 0.4, 0.6, 0.8])\n",
    "N2 = Neuron('Neuron 2', 0, [0.2, 0.4, 0.6, 0.8])\n",
    "N3 = Neuron('Neuron 3', 0, [0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "\n",
    "outputNeuron1 = Neuron('outputNeuron 1', 0,  [0.0, 0.1, 0.2])\n",
    "outputNeuron2 = Neuron('outputNeuron 2', 0,  [0.3, 0.4, 0.5])\n",
    "outputNeuron3 = Neuron('outputNeuron 3', 0,  [0.6, 0.7, 0.8])\n",
    "\n",
    "\n",
    "hiddenLayer1 = NeuronLayer('Hidden Layer1', [N1, N2, N3])\n",
    "outputLayer = NeuronLayer('Output Layer', [outputNeuron1, outputNeuron2, outputNeuron3])\n",
    "\n",
    "network_iris = NeuronNetwork([hiddenLayer1, outputLayer])\n",
    "print(network_iris)\n",
    "\n",
    "\n",
    "# print_table(test_iris, \"Verwachting\")\n",
    "\n",
    "old_output, old_outputs = create_table_data_iris(network_iris.feed_forward, test_iris)\n",
    "# print_table(old_output, 'Uitkomst VOOR training')\n",
    "print(f'Score [Voor training]: <{accuracy_score(list(targets_test), old_outputs)}>\\n')\n",
    "\n",
    "\n",
    "network_iris.train(train_iris, 200, 0.1)\n",
    "\n",
    "new_output, new_outputs = create_table_data_iris(network_iris.feed_forward, test_iris)\n",
    "# print_table(new_output, 'Uitkomst NA training')\n",
    "print(f'Score [Na training]: <{accuracy_score(list(targets_test), new_outputs)}>\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ik weet uiteindelijk een score van (vaak) 94% te halen, Toen ik eerst ging testen met startwaardes van bijvoorbeeld 1 was dit een stuk lager, dit doet dus blijken dat het naast een correct werkten leeralgoritme ook belangrijk is om de startwaardes goed te kiezen."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toevoeging, door iets werkte het getrainde netwerk opeens niet meer goed... nu komt hij niet verder dan 40..\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "data_digits = digits.images.reshape((n_samples, -1))\n",
    "targets_digits = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test / Train Split\"\"\"\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(data_digits, targets_digits, test_size=0.33, shuffle = True)\n",
    "\n",
    "targets_train = pd.get_dummies(targets_train).values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_digit = [list(x) for x in zip(features_train, targets_train)]\n",
    "test_digit = [list(x) for x in zip(features_test, targets_test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "<Hidden Layer 1> - Deze layer bestaat uit 25 neurons\n",
      "\n",
      "----------------------------------------\n",
      "<Output Layer> - Deze layer bestaat uit 10 neurons\n",
      "\n",
      "----------------------------------------\n",
      "Dit netwerk bestaat uit 2 layers\n",
      "\n",
      "Score [Voor training]: <0.02356902356902357>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\HU-Studie\\Machine-Learning\\Machine-Learning\\P4\\Neuron.py:25: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return 1 / (1 + e ** -weighted_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Het trainen van het Digit-Network met 15 epochs een een learning rate van 0.5 duurde:\n",
      " >43.45 Seconden\n",
      "\n",
      "Score [Na training]: <0.7407407407407407>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Digit Test\"\"\"\n",
    "\n",
    "hiddenNeurons = []\n",
    "for i in range(25): \n",
    "    hiddenNeurons.append(Neuron(f'hiddenNeuron {i}', 0, generate_random_list(64)))\n",
    "\n",
    "outputNeurons = []\n",
    "for i in range(10): # Er zijn 10 mogelijk targets\n",
    "    outputNeurons.append(Neuron(f'outputNeuron {i}', 0, generate_random_list(25)))\n",
    "\n",
    "hiddenLayer1 = NeuronLayer('Hidden Layer 1', hiddenNeurons)\n",
    "print(hiddenLayer1)\n",
    "outputLayer = NeuronLayer('Output Layer', outputNeurons)\n",
    "print(outputLayer)\n",
    "\n",
    "network_digit = NeuronNetwork([hiddenLayer1, outputLayer])\n",
    "print(network_digit)\n",
    "\n",
    "\n",
    "# print_table(test, \"Verwachting\")\n",
    "\n",
    "old_output, old_outputs = create_table_data_iris(network_digit.feed_forward, test_digit)\n",
    "# print_table(old_output, 'Uitkomst VOOR training')\n",
    "print(f'Score [Voor training]: <{accuracy_score(list(targets_test), old_outputs)}>\\n')\n",
    "\n",
    "epochs = 15\n",
    "learning_rate = 0.5\n",
    "\n",
    "start = timer()\n",
    "network_digit.train(train_digit, epochs, learning_rate)\n",
    "elapsed_time = timer() - start\n",
    "print(f'Het trainen van het Digit-Network met {epochs} epochs een een learning rate van {learning_rate} duurde:\\n >{round(elapsed_time,2)} Seconden\\n')\n",
    "\n",
    "new_output, new_outputs = create_table_data_iris(network_digit.feed_forward, test_digit)\n",
    "# print_table(new_output, 'Uitkomst NA training')\n",
    "print(f'Score [Na training]: <{accuracy_score(list(targets_test), new_outputs)}>\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlusie: \n",
    "Het trainen van een (nog relatief simpel) Netwerk kost veel tijd. Wel weet ik met de digit dataset soms een score van meer dan 75% te halen (ligt aan de test/train split & random gekozen parameters...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
